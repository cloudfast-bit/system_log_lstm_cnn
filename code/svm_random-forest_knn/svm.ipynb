{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, cross_validation, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset...\n",
      "Dataset loaded.\n"
     ]
    }
   ],
   "source": [
    "fault_label = {'1': 'info',\n",
    "               '2': 'Critical',\n",
    "               '3': 'error',\n",
    "               '4': 'notice',\n",
    "               '5': 'warning',\n",
    "               '6': 'alert',\n",
    "               '7': 'emergency'}\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "X_val = [] #validation set features\n",
    "y_val = [] #validation set target\n",
    "\n",
    "print(\"Opening dataset...\")\n",
    "try:\n",
    "    with open(\"data/msg_token_train.txt\", 'rU') as f:\n",
    "        res = list(f)\n",
    "        for line in res:\n",
    "            line.strip(\"\\n\")\n",
    "            features = line.split(\"\\t\")\n",
    "            while features.__contains__(\"\"):\n",
    "                features.remove(\"\")\n",
    "            for i in range(len(features)):\n",
    "                features[i] = float(features[i])\n",
    "            X.append(features)\n",
    "         \n",
    "    #read the classes from file and put them in list.      \n",
    "    with open(\"data/msg_label_train.txt\", 'rU') as f:\n",
    "        res = list(f)\n",
    "        for line in res:\n",
    "            y.append(int(line.strip(\"\\n\")[0]))\n",
    "            \n",
    "except:\n",
    "    print(\"Error in reading the train set file.\")\n",
    "    exit()\n",
    "try:\n",
    "    #do the same for test sets.\n",
    "    with open(\"data/msg_token_test.txt\", 'rU') as f:\n",
    "        res = list(f)\n",
    "        for line in res:\n",
    "            line.strip(\"\\n\")\n",
    "            features = line.split(\"\\t\")\n",
    "            while features.__contains__(\"\"):\n",
    "                features.remove(\"\")\n",
    "            for i in range(len(features)):\n",
    "                features[i] = float(features[i])\n",
    "            X_val.append(features)\n",
    "        \n",
    "    with open(\"data/msg_label_test.txt\", 'rU') as f:\n",
    "        res = list(f)\n",
    "        for line in res:\n",
    "            y_val.append(int(line.strip(\"\\n\")[0]))\n",
    "        f.close()\n",
    "except:\n",
    "    print(\"Error in reading the train set file.\")\n",
    "    exit()\n",
    "print(\"Dataset loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separating data into 67% training set & 33% test set...\n",
      "Dataset separated.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X) #change to matrix\n",
    "y = np.array(y) #change to matrix (sklearn models only accept matrices)\n",
    "\n",
    "# Separate our training data into test and training.\n",
    "print(\"Separating data into 67% training set & 33% test set...\")\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(\n",
    "    X, y, test_size=0.33, random_state=33)#add random state here...\n",
    "print(\"Dataset separated.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# svm-linear train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- SVM, Kernel = Linear --------------------------\n",
      "('C value chosen from: ', [1])\n",
      "Calculating accuracy with K-fold...\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------------------- SVM, Kernel = Linear --------------------------\")\n",
    "#C_linear = [0.1, 3, 10, 100...]\n",
    "C_linear = [1]\n",
    "result_linear = []\n",
    "\n",
    "print(\"C value chosen from: \", C_linear)\n",
    "print(\"Calculating accuracy with K-fold...\")\n",
    "\n",
    "for C in C_linear:\n",
    "    svc_linear = svm.SVC(kernel='linear', C=C)\n",
    "    scores = cross_validation.cross_val_score(\n",
    "        svc_linear, X_train, y_train, scoring='accuracy', cv=7)\n",
    "    result_linear.append(scores.mean())\n",
    "\n",
    "print(\"result:\", result_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# svm-linear test and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Result with different C are equal, so here choose C=1 directly as the best parameter.\n",
    "best_param_linear = {\"C\": 1}\n",
    "linear_test = svm.SVC(kernel='linear', C=best_param_linear.get(\"C\")).fit(X_train, y_train)\n",
    "linear_test_score = linear_test.score(X_test, y_test)\n",
    "\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "actualist = []\n",
    "predlist = []\n",
    "\n",
    "for i in range(len(X_val)):\n",
    "    count2 += 1\n",
    "    classinrow = X_val[i]\n",
    "    classinrow = np.array(X_val[i]).reshape(1,-1)\n",
    "    predicted = linear_test.predict(classinrow)#predict class.\n",
    "    actual = y_val[i]\n",
    "    actualist.append(actual)\n",
    "    predlist.append(predicted[0])\n",
    "    if predicted == actual:\n",
    "        count1 += 1\n",
    "\n",
    "print(\"Total cases: \", count2)\n",
    "print(\"Correct Prediction: \", count1)\n",
    "print(\"Correct prediction rate: \", float(count1) / count2)\n",
    "print(\"Linear Kernel test score: \", linear_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# svm-linear plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cmap can be changed to many colors, (colormaps.Oranges,OrRd, etc)\n",
    "def plot_CM(cm, title=\"Normalized Confusion Matrix\", cmap=plt.cm.Greens):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(fault_label))\n",
    "    plt.xticks(tick_marks, fault_label.values(), rotation=90)\n",
    "    plt.yticks(tick_marks, fault_label.values())\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.show()\n",
    "    \n",
    "print(metrics.classification_report(\n",
    "    actualist, predlist, target_names = list(fault_label.values())))\n",
    "cm = metrics.confusion_matrix(actualist, predlist)\n",
    "print(cm)\n",
    "\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:,np.newaxis]\n",
    "plt.figure()\n",
    "plot_CM(cm_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# svm-rbf train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"-------------------------- SVM, Kernel = RBF --------------------------\")\n",
    "#C_rbf = [0.1, 3, 10, 100...]\n",
    "C_rbf = [1]\n",
    "result_rbf = []\n",
    "\n",
    "print(\"C value chosen from: \", C_rbf)\n",
    "print(\"Calculating accuracy with K-fold...\")\n",
    "\n",
    "for C in C_rbf:\n",
    "    svc_rbf = svm.SVC(kernel='rbf', C=C)\n",
    "    scores = cross_validation.cross_val_score(\n",
    "        svc_rbf, X_train, y_train, scoring='accuracy', cv=7)\n",
    "    result_rbf.append(scores.mean())\n",
    "\n",
    "print(\"result:\", result_rbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# svm-rbf test and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Result with different C are equal, so here choose C=1 directly as the best parameter.\n",
    "best_param_rbf = {\"C\": 1}\n",
    "rbf_test = svm.SVC(kernel='rbf', C=best_param_rbf.get(\"C\")).fit(X_train, y_train)\n",
    "rbf_test_score = rbf_test.score(X_test, y_test)\n",
    "\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "actualist = []\n",
    "predlist = []\n",
    "\n",
    "for i in range(len(X_val)):\n",
    "    count2 += 1\n",
    "    classinrow = X_val[i]\n",
    "    classinrow = np.array(X_val[i]).reshape(1,-1)\n",
    "    predicted = rbf_test.predict(classinrow)#predict class.\n",
    "    actual = y_val[i]\n",
    "    actualist.append(actual)\n",
    "    predlist.append(predicted[0])\n",
    "    if predicted == actual:\n",
    "        count1 += 1\n",
    "\n",
    "print(\"Total cases: \", count2)\n",
    "print(\"Correct Prediction: \", count1)\n",
    "print(\"Correct prediction rate: \", float(count1) / count2)\n",
    "print(\"RBF Kernel test score: \", rbf_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# svm-rbf plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cmap can be changed to many colors, (colormaps.Oranges,OrRd, etc)\n",
    "def plot_CM(cm, title=\"Normalized Confusion Matrix\", cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(fault_label))\n",
    "    plt.xticks(tick_marks, fault_label.values(), rotation=90)\n",
    "    plt.yticks(tick_marks, fault_label.values())\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.show()\n",
    "    \n",
    "print(metrics.classification_report(\n",
    "    actualist, predlist, target_names = list(fault_label.values())))\n",
    "cm = metrics.confusion_matrix(actualist, predlist)\n",
    "print(cm)\n",
    "\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:,np.newaxis]\n",
    "plt.figure()\n",
    "plot_CM(cm_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# svm-poly train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"-------------------------- SVM, Kernel = Poly --------------------------\")\n",
    "#C_poly = [0.1, 3, 10, 100...]\n",
    "C_poly = [1]\n",
    "result_poly = []\n",
    "\n",
    "print(\"C value chosen from: \", C_poly)\n",
    "print(\"Calculating accuracy with K-fold...\")\n",
    "\n",
    "for C in C_poly:\n",
    "    svc_poly = svm.SVC(kernel='poly', C=C)\n",
    "    scores = cross_validation.cross_val_score(\n",
    "        svc_poly, X_train, y_train, scoring='accuracy', cv=7)\n",
    "    result_poly.append(scores.mean())\n",
    "\n",
    "print(\"result:\", result_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# svm-poly test and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Result with different C are equal, so here choose C=1 directly as the best parameter.\n",
    "best_param_poly = {\"C\": 1}\n",
    "poly_test = svm.SVC(kernel='poly', C=best_param_poly.get(\"C\"), degree=best_param_poly.get(\"degree\")).fit(X_train, y_train)\n",
    "poly_test_score = poly_test.score(X_test, y_test)\n",
    "\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "actualist = []\n",
    "predlist = []\n",
    "\n",
    "for i in range(len(X_val)):\n",
    "    count2 += 1\n",
    "    classinrow = X_val[i]\n",
    "    classinrow = np.array(X_val[i]).reshape(1,-1)\n",
    "    predicted = poly_test.predict(classinrow)#predict class.\n",
    "    actual = y_val[i]\n",
    "    actualist.append(actual)\n",
    "    predlist.append(predicted[0])\n",
    "    if predicted == actual:\n",
    "        count1 += 1\n",
    "\n",
    "print(\"Total cases: \", count2)\n",
    "print(\"Correct Prediction: \", count1)\n",
    "print(\"Correct prediction rate: \", float(count1) / count2)\n",
    "print(\"Poly Kernel test score: \", poly_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# svm-poly plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cmap can be changed to many colors, (colormaps.Oranges,OrRd, etc)\n",
    "def plot_CM(cm, title=\"Normalized Confusion Matrix\", cmap=plt.cm.RdYlGn):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(fault_label))\n",
    "    plt.xticks(tick_marks, fault_label.values(), rotation=90)\n",
    "    plt.yticks(tick_marks, fault_label.values())\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.show()\n",
    "    \n",
    "print(metrics.classification_report(\n",
    "    actualist, predlist, target_names = list(fault_label.values())))\n",
    "cm = metrics.confusion_matrix(actualist, predlist)\n",
    "print(cm)\n",
    "\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:,np.newaxis]\n",
    "plt.figure()\n",
    "plot_CM(cm_normalized)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
