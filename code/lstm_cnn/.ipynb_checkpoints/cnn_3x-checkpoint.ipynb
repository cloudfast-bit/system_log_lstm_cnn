{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation, metrics\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction = 0.4)\n",
    "sess_config = tf.ConfigProto(gpu_options=gpu_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = {'0':'file', '1':'network', '2':'service', '3':'database', '4':'communication', '5':'memory', '6':'driver', \n",
    "    '7':'system', '8':'application', '9':'io', '10':'others', '11':'security', '12':'disk', '13':'processor'}\n",
    "\n",
    "fault_label = {'0':'file', '1':'network', '2':'service', '3':'database', '4':'communication', '5':'memory', '6':'driver', \n",
    "    '7':'system', '8':'application', '9':'io', '10':'others', '11':'security', '12':'disk', '13':'processor'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separating data into 80% training set & 20% test set...\n",
      "Dataset separated.\n",
      "\n",
      "((80000, 10, 14, 1), (80000, 14), (20000, 14))\n"
     ]
    }
   ],
   "source": [
    "def one_hot(y):\n",
    "    y = y.reshape(len(y))\n",
    "    n_values = np.max(y) + 1\n",
    "    return np.eye(n_values)[np.array(y, dtype=np.int32)]  # Returns FLOATS\n",
    "\n",
    "\n",
    "def load_X(X_path):\n",
    "    X_list = []\n",
    "    file = open(X_path, 'r')\n",
    "    # Read dataset from disk, dealing with text files' syntax\n",
    "    X_signal = [np.array(item, dtype=np.float32) for item in [\n",
    "               line.strip().split('\\t') for line in file]]\n",
    "    X_list.append(X_signal)\n",
    "    file.close()\n",
    "    return np.transpose(np.array(X_list), (1, 2, 0))\n",
    "\n",
    "\n",
    "# Load \"y\" (the neural network's training and testing outputs)\n",
    "def load_y(y_path):\n",
    "    file = open(y_path, 'r')\n",
    "    # Read dataset from disk, dealing with text file's syntax\n",
    "    y_ = np.array([elem for elem in [line.strip().split('\\t') for line in file]], \n",
    "                  dtype=np.int32)\n",
    "    file.close()\n",
    "    # Substract 1 to each output class for friendly 0-based indexing\n",
    "    return one_hot(y_-1)\n",
    "\n",
    "\n",
    "dataset_path = \"data_msg_type/\"\n",
    "X_path = dataset_path + \"semantic_sim.txt\"\n",
    "y_path = dataset_path + \"semantic_label_index.txt\"\n",
    "\n",
    "X = load_X(X_path)\n",
    "y = load_y(y_path)\n",
    "x = X.reshape(len(X), 10, 14, 1)\n",
    "\n",
    "# Separate our training data into test and training.\n",
    "print(\"Separating data into 80% training set & 20% test set...\")\n",
    "train_x, test_x, train_y, test_y = cross_validation.train_test_split(\n",
    "    x, y, test_size=0.2, random_state=33)#add random state here...\n",
    "print(\"Dataset separated.\\n\")\n",
    "print(train_x.shape, train_y.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_iters = 80000\n",
    "test_iters = 2000000\n",
    "batch_size = 100\n",
    "display_step = 20000\n",
    "\n",
    "# Network Parameters\n",
    "input_height = 10\n",
    "input_width = 14\n",
    "num_channels = 1\n",
    "n_classes = 14\n",
    "dropout = 0.75 # Dropout, probability to keep units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# network config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some wrappers for simplicity\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    # MaxPool2D wrapper\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "\n",
    "\n",
    "# Create model\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    # Reshape input picture\n",
    "    x = tf.reshape(x, shape=[-1, 10, 14, 1])\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "    print(conv1.shape)\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "    print(conv2.shape)\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    print(fc1.shape)\n",
    "    \n",
    "    # Apply Dropout\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    print(out.shape)\n",
    "    return out\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    # 5x5 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([3, 4, 1, 32])),\n",
    "    # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.random_normal([3, 4, 32, 64])),\n",
    "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([3*4*64, 1024])),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5, 7, 32)\n",
      "(100, 3, 4, 64)\n",
      "(100, 1024)\n",
      "(100, 14)\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [100,input_height,input_width,num_channels])\n",
    "y = tf.placeholder(tf.float32, [100, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)\n",
    "\n",
    "pred = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epochs #100: Batch Loss = 17641.410156, Accuracy = 0.0499999970198\n",
      "Performance on test set: Batch Loss = 8584.83398438, Accuracy = 0.0\n",
      "Training epochs #20000: Batch Loss = 836.588379, Accuracy = 0.689999938011\n",
      "Performance on test set: Batch Loss = 327.353637695, Accuracy = 0.819999933243\n",
      "Training epochs #40000: Batch Loss = 258.569458, Accuracy = 0.840000092983\n",
      "Performance on test set: Batch Loss = 119.444000244, Accuracy = 0.879999995232\n",
      "Training epochs #60000: Batch Loss = 70.411011, Accuracy = 0.859999895096\n",
      "Performance on test set: Batch Loss = 73.3880081177, Accuracy = 0.870000004768\n",
      "Training epochs #80000: Batch Loss = 194.204254, Accuracy = 0.849999964237\n",
      "Performance on test set: Batch Loss = 36.0198135376, Accuracy = 0.939999997616\n",
      "Training epochs #100000: Batch Loss = 70.879562, Accuracy = 0.870000004768\n",
      "Performance on test set: Batch Loss = 29.154083252, Accuracy = 0.939999997616\n",
      "Training epochs #120000: Batch Loss = 18.262175, Accuracy = 0.94000005722\n",
      "Performance on test set: Batch Loss = 12.6073684692, Accuracy = 0.94000005722\n",
      "Training epochs #140000: Batch Loss = 12.691432, Accuracy = 0.960000038147\n",
      "Performance on test set: Batch Loss = 18.9826011658, Accuracy = 0.97000002861\n",
      "Training epochs #160000: Batch Loss = 78.571625, Accuracy = 0.910000026226\n",
      "Performance on test set: Batch Loss = 8.15806007385, Accuracy = 0.980000019073\n",
      "Training epochs #180000: Batch Loss = 8.468933, Accuracy = 0.97000002861\n",
      "Performance on test set: Batch Loss = 8.89428043365, Accuracy = 0.980000019073\n",
      "Training epochs #200000: Batch Loss = 3.550248, Accuracy = 0.980000019073\n",
      "Performance on test set: Batch Loss = 7.28552961349, Accuracy = 0.980000019073\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "def extract_batch_size(_train, step, batch_size):   \n",
    "    # Function to fetch a \"batch_size\" amount of data from \"(X|y)_train\" data.    \n",
    "    shape = list(_train.shape)\n",
    "    shape[0] = batch_size\n",
    "    batch_s = np.empty(shape)\n",
    "    for i in range(batch_size):\n",
    "        # Loop index\n",
    "        index = ((step-1)*batch_size + i) % len(_train)\n",
    "        batch_s[i] = _train[index] \n",
    "    return batch_s\n",
    "\n",
    "\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "test_predictions = []\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session(config=sess_config) as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size <= training_iters:\n",
    "        batch_xs = extract_batch_size(train_x, step, batch_size)\n",
    "        batch_ys = extract_batch_size(train_y, step, batch_size)\n",
    "\n",
    "        # Fit training using batch data\n",
    "        _, loss, acc = sess.run([optimizer, cost, accuracy],\n",
    "                       feed_dict={x: batch_xs, y: batch_ys, keep_prob: dropout})\n",
    "\n",
    "        train_losses.append(loss)\n",
    "        train_accuracies.append(acc)  \n",
    "\n",
    "        # Evaluate network only at some steps for faster training: \n",
    "        if (step*batch_size % display_step == 0) or (step == 1) \\\n",
    "            or (step * batch_size > training_iters):\n",
    "\n",
    "            print(\"Training epochs #\" + str(step*batch_size) + \\\n",
    "                  \": Batch Loss = \" + \"{:.6f}\".format(loss) + \\\n",
    "                  \", Accuracy = {}\".format(acc))\n",
    "            \n",
    "        step += 1\n",
    "        \n",
    "    step = 1\n",
    "    # test \n",
    "    while step * batch_size <= test_iters:\n",
    "        batch_xt = extract_batch_size(test_x, step, batch_size)\n",
    "        batch_yt = extract_batch_size(test_y, step, batch_size)\n",
    "    \n",
    "        # Evaluation on the test set (no learning made here - just evaluation for diagnosis)\n",
    "        test_predict, test_loss, test_acc = sess.run([pred, cost, accuracy], \n",
    "                                            feed_dict={x: batch_xt, y: batch_yt, keep_prob: 1.})\n",
    "        \n",
    "        test_predictions.append(test_predict)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_acc)\n",
    "        \n",
    "        # Evaluate network only at some steps: \n",
    "        if (step*batch_size % display_step == 0) or (step == 1) \\\n",
    "            or (step * batch_size > test_iters):\n",
    "        \n",
    "            print(\"Performance on test set: \" + \"Batch Loss = {}\".format(test_loss) + \\\n",
    "                  \", Accuracy = {}\".format(test_acc))\n",
    "\n",
    "    print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# performance visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEWCAYAAACufwpNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQVA3wqkEQRAEdSOcShAEQVA3/gbuVKlQSEogxwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9f3f1d03d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9f3c0938d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#font = {'family': 'Bitstream Vera Sans', 'weight': 'bold', 'size': 12}\n",
    "#matplotlib.rc('font', **font)\n",
    "#width = 12\n",
    "#height = 12\n",
    "#plt.figure(figsize=(width, height))\n",
    "\n",
    "indep_train_axis = np.array(range(batch_size, \n",
    "                   (len(train_losses)+1)*batch_size, batch_size))\n",
    "plt.plot(indep_train_axis, np.array(train_losses), \"b--\", label=\"Train losses\")\n",
    "plt.plot(indep_train_axis, np.array(train_accuracies), \"g--\", label=\"Train accuracies\")\n",
    "\n",
    "indep_test_axis = np.append(np.array(range(batch_size, \n",
    "    len(test_losses)*display_step, display_step)[:-1]), training_iters)\n",
    "\n",
    "plt.plot(indep_test_axis, np.array(test_losses), \"b-\", label=\"Test losses\")\n",
    "plt.plot(indep_test_axis, np.array(test_accuracies), \"g-\", label=\"Test accuracies\")\n",
    "\n",
    "plt.title(\"Training session's progress over iterations\")\n",
    "plt.legend(loc='upper right', shadow=False)\n",
    "plt.ylabel('Training Progress (Loss or Accuracy values)')\n",
    "plt.xlabel('Training iteration')\n",
    "plt.savefig('result/lstm_loss_accuracy.png')\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "Testing Accuracy: Tensor(\"mul_6:0\", shape=(), dtype=float32)%\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [20000, 2000]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-ab91543b1d3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m print(\"Precision: {}%\".format(100*metrics.precision_score(\n\u001b[0;32m---> 11\u001b[0;31m     test_y, predictions, average=\"weighted\")))\n\u001b[0m\u001b[1;32m     12\u001b[0m print(\"Recall: {}%\".format(100*metrics.recall_score(test_y, \n\u001b[1;32m     13\u001b[0m     predictions, average=\"weighted\")))\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1240\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 181\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [20000, 2000]"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "# Results\n",
    "predictions = test_predictions\n",
    "\n",
    "print(len(predictions))\n",
    "\n",
    "print(\"Testing Accuracy: {}%\".format(100*accuracy))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Precision: {}%\".format(100*metrics.precision_score(\n",
    "    test_y, predictions, average=\"weighted\")))\n",
    "print(\"Recall: {}%\".format(100*metrics.recall_score(test_y, \n",
    "    predictions, average=\"weighted\")))\n",
    "print(\"f1_score: {}%\".format(100*metrics.f1_score(test_y, \n",
    "    predictions, average=\"weighted\")))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix:\")\n",
    "confusion_matrix = metrics.confusion_matrix(test_y, predictions)\n",
    "print(confusion_matrix)\n",
    "\n",
    "# Plot: \n",
    "## cmap can be changed to many colors, (colormaps.Oranges,OrRd, etc)\n",
    "def plot_CM(cm, title=\"Normalized Confusion Matrix\", cmap=plt.cm.summer):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(fault_label))\n",
    "    plt.xticks(tick_marks, fault_label.values(), rotation=90)\n",
    "    plt.yticks(tick_marks, fault_label.values())\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.show()\n",
    "    \n",
    "print(metrics.classification_report(\n",
    "    y_test, predictions, target_names = list(fault_label.values())))\n",
    "\n",
    "cm = confusion_matrix\n",
    "\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:,np.newaxis]\n",
    "plt.figure()\n",
    "plot_CM(cm_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
