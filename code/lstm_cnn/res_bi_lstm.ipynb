{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lstm_architecture import one_hot, run_with_config\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# network config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    \"\"\"\n",
    "    define a class to store parameters,\n",
    "    the input should be feature mat of training and testing\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X_train, X_test):\n",
    "        # Data shaping\n",
    "        self.train_count = len(X_train)  # 7352 training series\n",
    "        self.test_data_count = len(X_test)  # 2947 testing series\n",
    "        self.n_steps = len(X_train[0])  # 128 time_steps per series\n",
    "        self.n_classes = 7  # Final output classes\n",
    "\n",
    "        # Training\n",
    "        self.learning_rate = 0.001\n",
    "        self.lambda_loss_amount = 0.005\n",
    "        self.training_epochs = 100\n",
    "        self.batch_size = 100\n",
    "        self.clip_gradients = 15.0\n",
    "        self.gradient_noise_scale = None\n",
    "        # Dropout is added on inputs and after each stacked layers (but not\n",
    "        # between residual layers).\n",
    "        self.keep_prob_for_dropout = 0.85  # **(1/3.0)\n",
    "\n",
    "        # Linear+relu structure\n",
    "        self.bias_mean = 0.3\n",
    "        # I would recommend between 0.1 and 1.0 or to change and use a xavier\n",
    "        # initializer\n",
    "        self.weights_stddev = 0.2\n",
    "\n",
    "        ########\n",
    "        # NOTE: I think that if any of the below parameters are changed,\n",
    "        # the best is to readjust every parameters in the \"Training\" section\n",
    "        # above to properly compare the architectures only once optimised.\n",
    "        ########\n",
    "\n",
    "        # LSTM structure\n",
    "        # Features count is of 9: three 3D sensors features over time\n",
    "        self.n_inputs = len(X_train[0][0])\n",
    "        self.n_hidden = 28  # nb of neurons inside the neural network\n",
    "        # Use bidir in every LSTM cell, or not:\n",
    "        self.use_bidirectionnal_cells = False\n",
    "\n",
    "        # High-level deep architecture\n",
    "        self.also_add_dropout_between_stacked_cells = False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset is now located at: data/\n",
      "((8360, 120, 1), (8360, 7), (1671, 7))\n"
     ]
    }
   ],
   "source": [
    "def load_X(X_path):\n",
    "    X_list = []\n",
    "    file = open(X_path, 'r')\n",
    "    # Read dataset from disk, dealing with text files' syntax\n",
    "    X_signal = [np.array(item, dtype=np.float32) for item in [\n",
    "               line.strip().split('\\t') for line in file]]\n",
    "    X_list.append(X_signal)\n",
    "    file.close()\n",
    "    return np.transpose(np.array(X_list), (1, 2, 0))\n",
    "\n",
    "\n",
    "# Load \"y\" (the neural network's training and testing outputs)\n",
    "def load_y(y_path):\n",
    "    file = open(y_path, 'r')\n",
    "    # Read dataset from disk, dealing with text file's syntax\n",
    "    y_ = np.array([elem for elem in [line.strip().split('\\t') for line in file]], \n",
    "                  dtype=np.int32)\n",
    "    file.close()\n",
    "    # Substract 1 to each output class for friendly 0-based indexing\n",
    "    return one_hot(y_)\n",
    "\n",
    "labels = ['info', 'crit', 'err', 'notice', 'warning', 'alert', 'emerg']\n",
    "\n",
    "dataset_path = \"data/\"\n",
    "print(\"\\n\" + \"Dataset is now located at: \" + dataset_path)\n",
    "\n",
    "X_train_signals_path = dataset_path + \"msg_token_train.txt\"\n",
    "X_test_signals_path = dataset_path + \"msg_token_test.txt\"\n",
    "X_train = load_X(X_train_signals_path)\n",
    "X_test = load_X(X_test_signals_path)\n",
    "\n",
    "y_train_path = dataset_path + \"msg_label_train.txt\"\n",
    "y_test_path = dataset_path + \"msg_label_test.txt\"\n",
    "\n",
    "y_train = load_y(y_train_path)\n",
    "y_test = load_y(y_test_path)\n",
    "print(X_train.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.001\n",
      "lambda_loss_amount: 0.005\n",
      "\n",
      "Some useful info to get an insight on dataset's shape and normalisation:\n",
      "features shape, labels shape, each features mean, each features standard deviation\n",
      "((1671, 120, 1), (1671, 7), 19643.785, 5585.6108)\n",
      "the dataset is therefore properly normalised, as expected.\n",
      "(120, ?, 1)\n",
      "(?, 1)\n",
      "(120, '(?, 1)')\n",
      "\n",
      "Creating hidden #1:\n",
      "(120, '(?, 28)')\n",
      "\n",
      "Creating hidden #2:\n",
      "(120, '(?, 28)')\n",
      "\n",
      "Creating hidden #3:\n",
      "(120, '(?, 28)')\n",
      "\n",
      "Unregularised variables:\n",
      "LSTM_network/layer_1/relu_fc_biases_noreg:0\n",
      "LSTM_network/layer_2/relu_fc_biases_noreg:0\n",
      "LSTM_network/layer_3/relu_fc_biases_noreg:0\n",
      "LSTM_network/relu_fc_biases_noreg:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0, train loss: 1.44182527065, train accuracy: 0.459999978542, train F1-score: 0.435858585859, test loss: 1.57855677605, test accuracy: 0.415320128202, test F1-score: 0.243748157539\n",
      "iter: 1, train loss: 1.24170589447, train accuracy: 0.459999978542, train F1-score: 0.389556451613, test loss: 1.41779947281, test accuracy: 0.436265677214, test F1-score: 0.265031418312\n",
      "iter: 2, train loss: 1.15945875645, train accuracy: 0.519999980927, train F1-score: 0.40947295423, test loss: 1.34869003296, test accuracy: 0.436265677214, test F1-score: 0.265031418312\n",
      "iter: 3, train loss: 1.12953484058, train accuracy: 0.42999997735, train F1-score: 0.383257918552, test loss: 1.31111299992, test accuracy: 0.436265677214, test F1-score: 0.265031418312\n",
      "iter: 4, train loss: 1.0831694603, train accuracy: 0.479999989271, train F1-score: 0.382935779817, test loss: 1.28837275505, test accuracy: 0.436265677214, test F1-score: 0.265031418312\n",
      "iter: 5, train loss: 1.05748581886, train accuracy: 0.490000009537, train F1-score: 0.42995862069, test loss: 1.2490260601, test accuracy: 0.415320128202, test F1-score: 0.243748157539\n",
      "iter: 6, train loss: 1.07231640816, train accuracy: 0.430000007153, train F1-score: 0.34544, test loss: 1.23416078091, test accuracy: 0.436265677214, test F1-score: 0.265031418312\n",
      "iter: 7, train loss: 1.06476533413, train accuracy: 0.420000016689, train F1-score: 0.379058908046, test loss: 1.22075140476, test accuracy: 0.436265677214, test F1-score: 0.265031418312\n",
      "iter: 8, train loss: 1.03212535381, train accuracy: 0.509999990463, train F1-score: 0.3951822947, test loss: 1.21469795704, test accuracy: 0.415320128202, test F1-score: 0.243748157539\n",
      "iter: 9, train loss: 1.0370477438, train accuracy: 0.409999996424, train F1-score: 0.435508072175, test loss: 1.20991551876, test accuracy: 0.436265677214, test F1-score: 0.265031418312\n",
      "iter: 10, train loss: 1.04059052467, train accuracy: 0.469999998808, train F1-score: 0.322991336069, test loss: 1.20722389221, test accuracy: 0.436265677214, test F1-score: 0.265031418312\n",
      "iter: 11, train loss: 1.04149591923, train accuracy: 0.499999970198, train F1-score: 0.365114899926, test loss: 1.20438742638, test accuracy: 0.436265677214, test F1-score: 0.265031418312\n",
      "iter: 12, train loss: 1.03095221519, train accuracy: 0.480000019073, train F1-score: 0.405613636364, test loss: 1.20375525951, test accuracy: 0.436265677214, test F1-score: 0.265031418312\n",
      "iter: 13, train loss: 1.03129899502, train accuracy: 0.5, train F1-score: 0.32700265252, test loss: 1.20338332653, test accuracy: 0.436265677214, test F1-score: 0.265031418312\n",
      "iter: 14, train loss: 1.03933274746, train accuracy: 0.409999996424, train F1-score: 0.418962962963, test loss: 1.20057785511, test accuracy: 0.436265677214, test F1-score: 0.265031418312\n",
      "iter: 15, train loss: 1.03250002861, train accuracy: 0.419999986887, train F1-score: 0.376692307692, test loss: 1.20007967949, test accuracy: 0.415320128202, test F1-score: 0.243748157539\n",
      "iter: 16, train loss: 1.03182482719, train accuracy: 0.449999988079, train F1-score: 0.293607125186, test loss: 1.19947004318, test accuracy: 0.415320128202, test F1-score: 0.243748157539\n",
      "iter: 17, train loss: 1.02291047573, train accuracy: 0.450000017881, train F1-score: 0.196486977589, test loss: 1.19892251492, test accuracy: 0.415320128202, test F1-score: 0.243748157539\n",
      "iter: 18, train loss: 1.02981936932, train accuracy: 0.439999997616, train F1-score: 0.429156142365, test loss: 1.19738101959, test accuracy: 0.436265677214, test F1-score: 0.265031418312\n",
      "iter: 19, train loss: 1.02361321449, train accuracy: 0.489999979734, train F1-score: 0.328110863332, test loss: 1.19723081589, test accuracy: 0.436265677214, test F1-score: 0.265031418312\n",
      "iter: 20, train loss: 1.01899826527, train accuracy: 0.499999970198, train F1-score: 0.370476190476, test loss: 1.19786310196, test accuracy: 0.436265677214, test F1-score: 0.265031418312\n",
      "iter: 21, train loss: 1.01342856884, train accuracy: 0.519999980927, train F1-score: 0.320181818182, test loss: 1.19728577137, test accuracy: 0.436265677214, test F1-score: 0.265031418312\n",
      "iter: 22, train loss: 1.02923357487, train accuracy: 0.490000009537, train F1-score: 0.342666666667, test loss: 1.19662070274, test accuracy: 0.436265677214, test F1-score: 0.265031418312\n",
      "iter: 23, train loss: 1.01538181305, train accuracy: 0.490000009537, train F1-score: 0.357464566929, test loss: 1.19534373283, test accuracy: 0.436265677214, test F1-score: 0.265031418312\n",
      "iter: 24, train loss: 1.02973556519, train accuracy: 0.489999979734, train F1-score: 0.252367149758, test loss: 1.19551897049, test accuracy: 0.436265677214, test F1-score: 0.265031418312\n",
      "iter: 25, train loss: 1.01426494122, train accuracy: 0.539999961853, train F1-score: 0.390693451368, test loss: 1.19470643997, test accuracy: 0.436265677214, test F1-score: 0.265031418312\n",
      "iter: 26, train loss: 1.01021027565, train accuracy: 0.499999970198, train F1-score: 0.301899280576, test loss: 1.19590270519, test accuracy: 0.436265677214, test F1-score: 0.265031418312\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c05b00fb9d53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m#     accuracy_out, best_accuracy = -1, -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             accuracy_out, best_accuracy, f1_score_out, best_f1_score = (\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0mrun_with_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEditedConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             )\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maccuracy_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_f1_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/stephen/Desktop/lstm_cnn/lstm_architecture.pyc\u001b[0m in \u001b[0;36mrun_with_config\u001b[0;34m(Config, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m    329\u001b[0m                         \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mshuffled_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                         \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mshuffled_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                         \u001b[0mis_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                     }\n\u001b[1;32m    333\u001b[0m                 )\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_layers_in_highway = 0\n",
    "n_stacked_layers = 3\n",
    "trial_name = \"{}x{}\".format(n_layers_in_highway, n_stacked_layers)\n",
    "\n",
    "for learning_rate in [0.001]:  # [0.01, 0.007, 0.001, 0.0007, 0.0001]:\n",
    "    for lambda_loss_amount in [0.005]:\n",
    "        for clip_gradients in [15.0]:\n",
    "            print \"learning_rate: {}\".format(learning_rate)\n",
    "            print \"lambda_loss_amount: {}\".format(lambda_loss_amount)\n",
    "            print \"\"\n",
    "\n",
    "            class EditedConfig(Config):\n",
    "                def __init__(self, X, Y):\n",
    "                    super(EditedConfig, self).__init__(X, Y)\n",
    "\n",
    "                    # Edit only some parameters:\n",
    "                    self.learning_rate = learning_rate\n",
    "                    self.lambda_loss_amount = lambda_loss_amount\n",
    "                    self.clip_gradients = clip_gradients\n",
    "                    # Architecture params:\n",
    "                    self.n_layers_in_highway = n_layers_in_highway\n",
    "                    self.n_stacked_layers = n_stacked_layers\n",
    "\n",
    "            # # Useful catch upon looping (e.g.: not enough memory)\n",
    "            # try:\n",
    "            #     accuracy_out, best_accuracy = run_with_config(EditedConfig)\n",
    "            # except:\n",
    "            #     accuracy_out, best_accuracy = -1, -1\n",
    "            accuracy_out, best_accuracy, f1_score_out, best_f1_score = (\n",
    "                run_with_config(EditedConfig, X_train, y_train, X_test, y_test)\n",
    "            )\n",
    "            print (accuracy_out, best_accuracy, f1_score_out, best_f1_score)\n",
    "\n",
    "            with open('{}_result_.txt'.format(trial_name), 'a') as f:\n",
    "                f.write(str(learning_rate) + ' \\t' + str(lambda_loss_amount) + \\\n",
    "                        ' \\t' + str(clip_gradients) + ' \\t' + str(accuracy_out) + \\\n",
    "                        ' \\t' + str(best_accuracy) + ' \\t' + str(f1_score_out) + \\\n",
    "                        ' \\t' + str(best_f1_score) + '\\n\\n')\n",
    "\n",
    "            print \"______________________________________\"\n",
    "        print \"\"\n",
    "print \"Done.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
